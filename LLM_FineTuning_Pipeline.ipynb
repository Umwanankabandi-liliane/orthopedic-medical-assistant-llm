{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92028238",
   "metadata": {
    "id": "92028238"
   },
   "source": [
    "# ü©∫ Domain-Specific Assistant via LLM Fine-Tuning (Orthopedic Medical Assistant)\n",
    "\n",
    "**Domain:** Orthopedics / musculoskeletal conditions (fractures, joints, ligaments, rehabilitation)  \n",
    "**Dataset:** `medalpaca/medical_meadow_medical_flashcards` (Hugging Face)  \n",
    "**Model:** `TinyLlama/TinyLlama-1.1B-Chat-v1.0` using **QLoRA** (4-bit) + **LoRA**\n",
    "\n",
    "This Colab notebook includes:\n",
    "- Dataset loading + orthopedic filtering\n",
    "- Preprocessing + tokenization\n",
    "- **3 experiments** (hyperparameter tuning) + comparison table\n",
    "- Evaluation (eval loss + ROUGE-L + qualitative tests)\n",
    "- Base vs fine-tuned comparison\n",
    "- Gradio UI demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418685c8",
   "metadata": {
    "id": "418685c8"
   },
   "source": [
    "## 1) Install dependencies\n",
    "*(Install libraries for fine-tuning, evaluation, and UI.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656dd50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e656dd50",
    "outputId": "82e1fd0f-204c-42ce-d304-bef447b81ce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m515.2/515.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.7/60.7 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U transformers datasets peft accelerate bitsandbytes rouge-score sacrebleu gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542b4d28",
   "metadata": {
    "id": "542b4d28"
   },
   "source": [
    "## 2) Imports + GPU check\n",
    "*(Import required modules and confirm GPU availability.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0265eb52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0265eb52",
    "outputId": "d495fc98-ad2f-49a9-cb43-4a4b135dbb7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.0+cu128\n",
      "CUDA available: True\n",
      "GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import os, re, inspect\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,\n",
    "    TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import LoraConfig, TaskType, prepare_model_for_kbit_training, get_peft_model\n",
    "from rouge_score import rouge_scorer\n",
    "import gradio as gr\n",
    "\n",
    "print('Torch:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433776d",
   "metadata": {
    "id": "d433776d"
   },
   "source": [
    "## 3) Project definition (Rubric: Domain alignment)\n",
    "*(Purpose, users, and why fine-tuning is needed.)*\n",
    "\n",
    "- **Purpose:** Answer orthopedic/musculoskeletal study questions in a structured flashcard style.\n",
    "- **Users:** Students/trainees revising fractures, joint injuries, and rehabilitation basics.\n",
    "- **Why fine-tune:** Base LLMs can be generic; fine-tuning aligns outputs to domain-specific Q&A style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98dbfde",
   "metadata": {
    "id": "d98dbfde"
   },
   "source": [
    "## 4) Load dataset\n",
    "*(Load Medical Meadow medical flashcards from Hugging Face.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9920d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381,
     "referenced_widgets": [
      "db59f6a0b5e04ed69bde229fc062d119",
      "57275af1d72a4840ac4fe36688e54e24",
      "defa127f59ba4bfc84cf910f4439943f",
      "f2bbc57484dd4ec19c713c6ccd3c0850",
      "cf4f2a097833433daf89bd3dfffe4722",
      "939add60bded4588a89b9839500f3e9d",
      "924a3ff89e4542fa99e2d727a8a7bbf4",
      "e2b930642e6a4a42a97c66614d08a600",
      "4e38998945164a30aebd241535a5938e",
      "21d304f22c4f44fcb9610cca486738e3",
      "bdc53291004b457091032869d39f97a4",
      "8e950d80a2c74190842774d3743971a0",
      "7799e5502c444834ba70c724ff50943a",
      "ad4bb7eaa82848d09786deaa9230eb0f",
      "7f31c8fc48664a31a3b81e0fa1c3c2f8",
      "39a7d494af4b4cf0b3917c881676ccb3",
      "693a1a793c55472c846e274fbd81e3ed",
      "dc43895e675c4e2a9d52a4c35fba6be6",
      "9c3feca0e48942aea251bd2140cef3ad",
      "61c286d3269941578ec373b52f5db0a4",
      "576815f080c0416a9be8989311c97998",
      "c3ce10a4e8154b8aa4ac873d6ec14c30",
      "2c5a82f65d2241429812159454205de8",
      "18803646567a4eeda7811c5009b6a5af",
      "753f20490ae6452ba5d437995ab19f39",
      "8ddf344ddd664956acb8ccc5a0531983",
      "6e0e4880a2114529947efc140b7310cf",
      "a88522173c814c2498c462d6d48c3503",
      "fdd1aa42897e4b958cd4fd8e34248506",
      "e4f3b75a37954c319405217c03f84df5",
      "c2f1b46f31dc4d8e8f41cf9f7454f237",
      "88a5339f87604a5c83d0b9e59c0f1a72",
      "6358a71cb7bd4581af59cd517e2e2429"
     ]
    },
    "id": "4f9920d8",
    "outputId": "2388135b-3bad-4de7-addb-8a765ed2c6a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db59f6a0b5e04ed69bde229fc062d119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e950d80a2c74190842774d3743971a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "medical_meadow_wikidoc_medical_flashcard(‚Ä¶):   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5a82f65d2241429812159454205de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/33955 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 33955\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 33955,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33289,\n        \"samples\": [\n          \"In cloning, what is the next step after the production of cDNA, and what is the purpose of the vector used in this step?\",\n          \"What is testicular torsion and what are the typical symptoms that are seen in adolescents?\",\n          \"What is the cause of the midsystolic click in a murmur due to mitral valve prolapse?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33335,\n        \"samples\": [\n          \"Methylmercury is the compound found in swordfish, shark, and king mackerel that is known to cause neurotoxicity in the fetus.\",\n          \"The adrenal medulla is of neural crest origin.\",\n          \"Seizures can occur secondary to low blood sugar.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Answer this question truthfully\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-37304f83-c504-4d89-bf81-e6c6e3b6cc4f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>response</th>\n",
       "      <th>instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the relationship between very low Mg2+...</td>\n",
       "      <td>Very low Mg2+ levels correspond to low PTH lev...</td>\n",
       "      <td>Answer this question truthfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What leads to genitourinary syndrome of menopa...</td>\n",
       "      <td>Low estradiol production leads to genitourinar...</td>\n",
       "      <td>Answer this question truthfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does low REM sleep latency and experienci...</td>\n",
       "      <td>Low REM sleep latency and experiencing halluci...</td>\n",
       "      <td>Answer this question truthfully</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37304f83-c504-4d89-bf81-e6c6e3b6cc4f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-37304f83-c504-4d89-bf81-e6c6e3b6cc4f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-37304f83-c504-4d89-bf81-e6c6e3b6cc4f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  What is the relationship between very low Mg2+...   \n",
       "1  What leads to genitourinary syndrome of menopa...   \n",
       "2  What does low REM sleep latency and experienci...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Very low Mg2+ levels correspond to low PTH lev...   \n",
       "1  Low estradiol production leads to genitourinar...   \n",
       "2  Low REM sleep latency and experiencing halluci...   \n",
       "\n",
       "                       instruction  \n",
       "0  Answer this question truthfully  \n",
       "1  Answer this question truthfully  \n",
       "2  Answer this question truthfully  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('medalpaca/medical_meadow_medical_flashcards', split='train')\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Standardize common column name variants\n",
    "if 'instruction' in df.columns and 'output' in df.columns:\n",
    "    df = df.rename(columns={'output': 'response'})\n",
    "elif 'question' in df.columns and 'answer' in df.columns:\n",
    "    df = df.rename(columns={'question': 'instruction', 'answer': 'response'})\n",
    "elif 'input' in df.columns and 'output' in df.columns:\n",
    "    df = df.rename(columns={'input': 'instruction', 'output': 'response'})\n",
    "\n",
    "assert {'instruction','response'}.issubset(df.columns), df.columns.tolist()\n",
    "print('Original dataset size:', len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd823e2",
   "metadata": {
    "id": "7dd823e2"
   },
   "source": [
    "## 5) Filter orthopedic content\n",
    "*(Narrow to orthopedic/musculoskeletal topics for stronger domain focus.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b6d9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "0a9b6d9b",
    "outputId": "8bd8d4ac-eedc-467d-9496-727543586f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 2892 out of 33955\n",
      "Percent retained: 8.52 %\n",
      "Final dataset size used: 2892\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_use\",\n  \"rows\": 2892,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2869,\n        \"samples\": [\n          \"What condition is suggested by morning stiffness/pain lasting more than one hour that improves with use, systemic symptoms, and a woman aged 40-50?\",\n          \"With which form of Burkitt's lymphoma is the Epstein-Barr Virus associated?\",\n          \"Following a clavicular fracture, which nerve bundle should be examined for injury?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2880,\n        \"samples\": [\n          \"The subspecies of Trypanosoma brucei that is from East Africa is Trypanosoma brucei rhodesiense. This subspecies is responsible for causing African trypanosomiasis, also known as sleeping sickness, in humans. It is transmitted through the bite of the tsetse fly and can cause a range of symptoms, including fever, headaches, joint pain, and sleep disturbances. If left untreated, it can lead to more severe neurological symptoms and even death. African trypanosomiasis is a significant public health concern in many parts of sub-Saharan Africa, and efforts are ongoing to develop better diagnostic tools and treatments for this disease.\",\n          \"The major toxicity or side effect associated with mycophenolate is bone marrow suppression.\",\n          \"What should be evaluated when a patient has facial fractures and closed head injuries? The cervical spine should always be evaluated in such cases.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Answer this question truthfully\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_use"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-fd91bb4e-cd95-430b-bbeb-a6dcea036d36\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>response</th>\n",
       "      <th>instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the conditions that can be suggested ...</td>\n",
       "      <td>The presence of monosodium urate crystals in j...</td>\n",
       "      <td>Answer this question truthfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What conditions are suggested by high ESR/CK a...</td>\n",
       "      <td>High ESR/CK and bilateral proximal muscle weak...</td>\n",
       "      <td>Answer this question truthfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Œ≤-thalassemia major and how does it af...</td>\n",
       "      <td>Œ≤-thalassemia major is a specific type of Œ≤-th...</td>\n",
       "      <td>Answer this question truthfully</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd91bb4e-cd95-430b-bbeb-a6dcea036d36')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-fd91bb4e-cd95-430b-bbeb-a6dcea036d36 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-fd91bb4e-cd95-430b-bbeb-a6dcea036d36');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  What are the conditions that can be suggested ...   \n",
       "1  What conditions are suggested by high ESR/CK a...   \n",
       "2  What is Œ≤-thalassemia major and how does it af...   \n",
       "\n",
       "                                            response  \\\n",
       "0  The presence of monosodium urate crystals in j...   \n",
       "1  High ESR/CK and bilateral proximal muscle weak...   \n",
       "2  Œ≤-thalassemia major is a specific type of Œ≤-th...   \n",
       "\n",
       "                       instruction  \n",
       "0  Answer this question truthfully  \n",
       "1  Answer this question truthfully  \n",
       "2  Answer this question truthfully  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthopedic_keywords = [\n",
    "    'fracture','bone','orthopedic','orthopaedic','musculoskeletal',\n",
    "    'cast','splint','dislocation','sprain','strain','ligament','tendon',\n",
    "    'joint','cartilage','osteoporosis','arthritis',\n",
    "    'hip','knee','shoulder','elbow','wrist','ankle','spine','vertebra',\n",
    "    'femur','tibia','fibula','radius','ulna','rehabilitation','physical therapy'\n",
    "]\n",
    "\n",
    "def contains_keywords(text):\n",
    "    if pd.isna(text) or text is None:\n",
    "        return False\n",
    "    t = str(text).lower()\n",
    "    return any(k in t for k in orthopedic_keywords)\n",
    "\n",
    "mask = df['instruction'].apply(contains_keywords) | df['response'].apply(contains_keywords)\n",
    "df_filtered = df[mask].copy().reset_index(drop=True)\n",
    "\n",
    "print('Filtered dataset size:', len(df_filtered), 'out of', len(df))\n",
    "print('Percent retained:', round(100*len(df_filtered)/len(df), 2), '%')\n",
    "\n",
    "# If too small, fall back to full dataset\n",
    "df_use = df_filtered if len(df_filtered) >= 500 else df.copy()\n",
    "if len(df_use) != len(df_filtered):\n",
    "    print('Filtered set < 500 examples; using full dataset instead.')\n",
    "print('Final dataset size used:', len(df_use))\n",
    "df_use.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1f4818",
   "metadata": {
    "id": "9a1f4818"
   },
   "source": [
    "## 6) Preprocess text\n",
    "*(Clean/normalize text, remove duplicates, and filter very short entries.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13063180",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "13063180",
    "outputId": "5a7e1ab0-fff0-44f6-8dc2-b1201033d9c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing: 2892\n",
      "After preprocessing: 1145\n",
      "Removed: 1747\n",
      "\n",
      "Instruction length stats:\n",
      " count    1145.0\n",
      "mean       31.0\n",
      "std         0.0\n",
      "min        31.0\n",
      "25%        31.0\n",
      "50%        31.0\n",
      "75%        31.0\n",
      "max        31.0\n",
      "Name: instruction, dtype: float64\n",
      "\n",
      "Response length stats:\n",
      " count    1145.000000\n",
      "mean      161.791266\n",
      "std       116.375467\n",
      "min        11.000000\n",
      "25%        90.000000\n",
      "50%       120.000000\n",
      "75%       177.000000\n",
      "max       511.000000\n",
      "Name: response, dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_processed\",\n  \"rows\": 1145,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1140,\n        \"samples\": [\n          \"What is one benign cause of a 'coin-lesion' on a chest X-ray (CXR), and what is a brief description of this condition including the type of tissue it involves?\",\n          \"Which organs or tissues are affected by toxicity caused by ganciclovir?\",\n          \"Following a clavicular fracture, which nerve bundle should be examined for injury?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1145,\n        \"samples\": [\n          \"The referred pain in cases of acute cholecystitis is typically felt in the right shoulder or scapula.\",\n          \"Mycophenolate mofetil can be used to treat Rheumatoid Arthritis.\",\n          \"The axillary nerve and posterior humeral circumflex artery pass through the quadrangular space of the shoulder. This space is bordered by the teres minor muscle, teres major muscle, long head of the triceps brachii muscle, and the surgical neck of the humerus.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Answer this question truthfully\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_processed"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3a636f2d-d1d6-4aaf-b4ea-fcb6f6b4213e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>response</th>\n",
       "      <th>instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the conditions that can be suggested ...</td>\n",
       "      <td>The presence of monosodium urate crystals in j...</td>\n",
       "      <td>Answer this question truthfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What conditions are suggested by high ESR/CK a...</td>\n",
       "      <td>High ESRCK and bilateral proximal muscle weakn...</td>\n",
       "      <td>Answer this question truthfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Œ≤-thalassemia major and how does it af...</td>\n",
       "      <td>Œ≤-thalassemia major is a specific type of Œ≤-th...</td>\n",
       "      <td>Answer this question truthfully</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a636f2d-d1d6-4aaf-b4ea-fcb6f6b4213e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3a636f2d-d1d6-4aaf-b4ea-fcb6f6b4213e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3a636f2d-d1d6-4aaf-b4ea-fcb6f6b4213e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  What are the conditions that can be suggested ...   \n",
       "1  What conditions are suggested by high ESR/CK a...   \n",
       "2  What is Œ≤-thalassemia major and how does it af...   \n",
       "\n",
       "                                            response  \\\n",
       "0  The presence of monosodium urate crystals in j...   \n",
       "1  High ESRCK and bilateral proximal muscle weakn...   \n",
       "2  Œ≤-thalassemia major is a specific type of Œ≤-th...   \n",
       "\n",
       "                       instruction  \n",
       "0  Answer this question truthfully  \n",
       "1  Answer this question truthfully  \n",
       "2  Answer this question truthfully  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text) or text is None:\n",
    "        return ''\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s\\.\\,\\!\\?\\;\\:\\-\\(\\)]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def normalize_text(text):\n",
    "    if pd.isna(text) or text is None:\n",
    "        return ''\n",
    "    text = str(text)\n",
    "    return (text\n",
    "            .replace('\\u2019', \"'\")\n",
    "            .replace('\\u201c', '\"')\n",
    "            .replace('\\u201d', '\"')\n",
    "            .replace('\\u2013', '-')\n",
    "           )\n",
    "\n",
    "def preprocess_dataset(df_in, min_length=10, max_length=512):\n",
    "    df2 = df_in.copy()\n",
    "    df2['instruction'] = df2['instruction'].apply(lambda x: normalize_text(clean_text(x)))\n",
    "    df2['response'] = df2['response'].apply(lambda x: normalize_text(clean_text(x)))\n",
    "    before = len(df2)\n",
    "    df2 = df2[(df2['instruction'].str.len() >= min_length) & (df2['response'].str.len() >= min_length)]\n",
    "    df2 = df2[(df2['instruction'].str.len() <= max_length) & (df2['response'].str.len() <= max_length)]\n",
    "    df2 = df2.drop_duplicates(subset=['instruction','response']).reset_index(drop=True)\n",
    "    after = len(df2)\n",
    "    print('Before preprocessing:', before)\n",
    "    print('After preprocessing:', after)\n",
    "    print('Removed:', before - after)\n",
    "    return df2\n",
    "\n",
    "df_processed = preprocess_dataset(df_use, min_length=10, max_length=512)\n",
    "print('\\nInstruction length stats:\\n', df_processed['instruction'].str.len().describe())\n",
    "print('\\nResponse length stats:\\n', df_processed['response'].str.len().describe())\n",
    "df_processed.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e029e4",
   "metadata": {
    "id": "94e029e4"
   },
   "source": [
    "## 7) Train/validation split\n",
    "*(Shuffle and split into 90% train and 10% validation.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e3f955",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00e3f955",
    "outputId": "23794a72-4b37-4f82-fac9-891733546136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1031 examples\n",
      "Validation: 114 examples\n"
     ]
    }
   ],
   "source": [
    "df_shuffled = df_processed.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_size = int(len(df_shuffled) * 0.1)\n",
    "\n",
    "val_df = df_shuffled.iloc[:val_size].reset_index(drop=True)\n",
    "train_df = df_shuffled.iloc[val_size:].reset_index(drop=True)\n",
    "\n",
    "print(f'Train: {len(train_df)} examples')\n",
    "print(f'Validation: {len(val_df)} examples')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d8a101",
   "metadata": {
    "id": "56d8a101"
   },
   "source": [
    "## 8) Tokenizer + formatting\n",
    "*(Load tokenizer and format instruction-response pairs in Alpaca style.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4fd677",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246,
     "referenced_widgets": [
      "02a0ec7a7fb34a2296b51988587987e3",
      "6d9e68043fa04861a17cd0b61ee1b802",
      "5e3e595c426d4c6eb1ce90484455fcf2",
      "8e9d530763d2471da54560e5ffbb794d",
      "0e44f6c26901407bbdbc34a92ef493da",
      "fc774b579f2e459785b9c88ead9cb76c",
      "7077809a7d294bb9851494fb0ed35c3b",
      "558e8d6cfb6b4c669463b16a6b37fac2",
      "217ee85b33114ddda7fa6a3fed6a06aa",
      "ce17bbac53a84930b60678c9ff2dba34",
      "3567763652da48909b4bbfc1b3785252",
      "58ece4f95ab04c7e8d31f1e14c4c2ee9",
      "5e6eedc7c4ca4626a8e9b7a065791fd2",
      "1551f55f32044fea986eeba2f5e5deb0",
      "339987789695417cae5a0bdcc330032a",
      "97e72b550dc049dcb1a363c70302ab86",
      "b3091a6cc4254954a198e355a5064afd",
      "f94e106b7dfe40a4be38a99a25f30768",
      "6bef4166cf5f4828a7dd1559fe6ca6fd",
      "5abd1b8ea2764899ba50685d5c099a2b",
      "60cc1c9e47ae456cbc83653b5659af0c",
      "ddd38dc732524a158d1a3c8fc605a283",
      "d644f3879eb14faa8ef824dcb5400a6a",
      "11c29821bad64d69b4a4b27bb76f4602",
      "52e4af38faac4c5fb201ea528e70a7df",
      "775b2024264a405c95c6fc57c64c9c41",
      "699ffbe3378a4f39a1d761829b48057c",
      "9237286fccc849c580926dd74fc9faae",
      "664575a9bb0b4d24825730b074d87f45",
      "eb419b28f7b449d9a4506ef3516caddb",
      "c2d92397fa164c0fa0d63f0cab053fb2",
      "c2207484ddb74a248bccb875bca921ab",
      "4c564f0a26ef4a2fb1e7391e178f5ebc",
      "1bc032e1c8824c5699d13c12ebee19c5",
      "81d8c01546dc4c939cd88316cb29cfbb",
      "2ce92b482b3743f5878de3662b002dfc",
      "273f2223d29a4b52ade9cd9d5cf6af6e",
      "ed7ef1956c794fa8b5f4435c46e8b3db",
      "3b89b8008a8e4949922b59f4f0fb21fe",
      "714bf0e0263840ccb10efaa118050c6a",
      "236e6c59e6f04bf39b24f6e0dae16cf0",
      "28266f07015e427ab83e9fc160b2efa9",
      "4fc01827a1004215843fdc6c5864cc11",
      "d1e6e79b19f8498093b942e5c3acb39e",
      "7a0457f43d6d42ff8cbf5e14e7ac83f6",
      "231ee707fa16444e85b1b2d5fc36712f",
      "9e81fb211d0f43e2bae0fe9a7550f3af",
      "453f7b2d71d943e394159ffb0354aa44",
      "65cabb445e924a42afecc7354e7a35bd",
      "9834e2e9780d4e83ba4049a0d937f71f",
      "972b03af6eae4eb1aad423ebfc33743f",
      "4a9ae44b4e074a029ba31aa380ab6622",
      "12ca3fec124849a092bee2df42a71b3d",
      "b5d16cb9e0614a75a8ece1a985dbed45",
      "76f73cc9c3844181964d2c00107f3b4a"
     ]
    },
    "id": "8b4fd677",
    "outputId": "ad57d963-5bc8-417e-ae31-09eeca4cc721"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a0ec7a7fb34a2296b51988587987e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ece4f95ab04c7e8d31f1e14c4c2ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d644f3879eb14faa8ef824dcb5400a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc032e1c8824c5699d13c12ebee19c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0457f43d6d42ff8cbf5e14e7ac83f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "Vocab size: 32000\n"
     ]
    }
   ],
   "source": [
    "model_name = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "print('Tokenizer loaded:', model_name)\n",
    "print('Vocab size:', tokenizer.vocab_size)\n",
    "\n",
    "def format_instruction_response(instruction, response):\n",
    "    return (\n",
    "        'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n'\n",
    "        '### Instruction:\\n'\n",
    "        f'{instruction}\\n\\n'\n",
    "        '### Response:\\n'\n",
    "        f'{response}'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925c7893",
   "metadata": {
    "id": "925c7893"
   },
   "source": [
    "## 9) Convert to HF Dataset + tokenize\n",
    "*(Tokenize and set labels for causal LM training.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87ba09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "1c4f0e5035dc46899e4962eb5619ce2a",
      "fdc5882aacc44ec384a9f82bc6b6a53a",
      "fcc0861f52ca4367bb968c6752a9c5e8",
      "79a206366f44461b85e7221270eda845",
      "894786588c6948b58465b24210d95a5c",
      "983c8e153a32423d98e85d7916a4cfdf",
      "bd7d67a44fab49a28209d5919ce9fc6f",
      "ebe4130ca35c4a62a8721de68370ba17",
      "88822e5f2446476c8c368f98d5a84c62",
      "7bae4803562a4de3a796e4056ded574c",
      "bc3e07aed1694795b2f9889d703b7a60",
      "ff9bcc4754dc40878d18b389036efdc1",
      "831a09343e384bc4949faa6333f269c6",
      "e58c8984a5764da5b05dbad3f1fc0d03",
      "298a62fa4c224493ac98670ca7a84e8b",
      "6904eb3d81db42a481bf559152aacefb",
      "1e72a3710b6e46ab9b2bcaaafef642ca",
      "38a8202d1b0e48138cef5c7addf0d206",
      "f0a883a3b25347988130a9eb4c9b0196",
      "0a17a83137f646bca9c2fc4ef2faefe8",
      "52b3229ddcfd44bcb41e5f0df88ef6b7",
      "d77854343ca64d2ebcbb328e733ad937"
     ]
    },
    "id": "2f87ba09",
    "outputId": "d0218071-b5de-493b-9d3c-09c4fa8c7654"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4f0e5035dc46899e4962eb5619ce2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1031 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9bcc4754dc40878d18b389036efdc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized train: 1031\n",
      "Tokenized validation: 114\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples, max_length=512):\n",
    "    texts = [format_instruction_response(i, r) for i, r in zip(examples['instruction'], examples['response'])]\n",
    "    tok = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length)\n",
    "    tok['labels'] = tok['input_ids'].copy()\n",
    "    return tok\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "train_tokenized = train_dataset.map(lambda x: tokenize_function(x, 512), batched=True, remove_columns=train_dataset.column_names)\n",
    "val_tokenized = val_dataset.map(lambda x: tokenize_function(x, 512), batched=True, remove_columns=val_dataset.column_names)\n",
    "\n",
    "dataset_dict = DatasetDict({'train': train_tokenized, 'validation': val_tokenized})\n",
    "print('Tokenized train:', len(dataset_dict['train']))\n",
    "print('Tokenized validation:', len(dataset_dict['validation']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348c62e",
   "metadata": {
    "id": "e348c62e"
   },
   "source": [
    "## 10) TrainingArguments compatibility helper\n",
    "*(Auto-handle `eval_strategy` vs `evaluation_strategy` based on your transformers version.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7927ea8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7927ea8",
    "outputId": "735ee9e4-8db1-4cca-9d4c-221315ddfe0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supports evaluation_strategy: False\n"
     ]
    }
   ],
   "source": [
    "def make_training_args(**kwargs):\n",
    "    sig = inspect.signature(TrainingArguments.__init__)\n",
    "    params = sig.parameters.keys()\n",
    "    if 'evaluation_strategy' in params and 'eval_strategy' in kwargs:\n",
    "        kwargs['evaluation_strategy'] = kwargs.pop('eval_strategy')\n",
    "    if 'evaluation_strategy' not in params and 'evaluation_strategy' in kwargs:\n",
    "        kwargs['eval_strategy'] = kwargs.pop('evaluation_strategy')\n",
    "    return TrainingArguments(**kwargs)\n",
    "\n",
    "print('Supports evaluation_strategy:', 'evaluation_strategy' in inspect.signature(TrainingArguments.__init__).parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ad76c",
   "metadata": {
    "id": "379ad76c"
   },
   "source": [
    "## 11) Load base model (4-bit) for QLoRA\n",
    "*(Load TinyLlama with 4-bit NF4 quantization.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c9256",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "c4bc35adc37a4909ab43f832e32f157e",
      "4b87baf79f194b8498f8a918ba4bbdb6",
      "aab0e0e6c24f4efc9bdd5dfaae9423f1",
      "d20110b33c7b44c5989fc58f62e09a24",
      "5fe1254e8dc1430db8728566ad2958b4",
      "632f89183e404bb38416d61afa948e58",
      "2aeb579d8489439caa5c60f2c6693b1d",
      "e32068ad742d45a48758c211105e4034",
      "48baba769ca544e391b50795e27eb2a4",
      "a9c0b306d42140eeb170c933f15fa71d",
      "ccaf6df9ef5a4f28885c965790af8702",
      "9b8943fc4402438ea6d0ec712f57a2c9",
      "c357832302d44b0baf985794c49a222b",
      "d81c3e9bc0384fde9881cd4ea972145d",
      "148da315f963431ba1a6bc8e17b50745",
      "e9ca01d1bf8f405781cb20538213a554",
      "c2322d607ac44a62a0abbed09a4a42f4",
      "7dea6ee23f8d4d298d1b7a9d7083bd0b",
      "a72dd8cd970d4a6b817ef28f4659cceb",
      "056545b6b962488dada5ce5fa530b75a",
      "ac80e77992b24e22b842c02db578ef81",
      "163239159ae24b038d30e3eab8a19916",
      "2f1ba4805d684b1aa47ac08233c813d8",
      "d105274136bd4df4abcbfc89ba40813a",
      "f2d689ed99884a84a1a315e5cdf35d37",
      "0e46af87793148aab52141d255d8e0c4",
      "13186b950a624ab6981470184f6556ba",
      "6d5ec2699a694c8db24111741ac8eb3d",
      "6c33b34da2064cf48f285e65b5e85a37",
      "f209d68f4b9a4dd8a09c6437923bd7e0",
      "21d9ec780f754c9a8ffc018702363191",
      "a9286ad8cd8d43daa5a5b65fe7caab5d",
      "b4704916dee243cea9480d686927666c"
     ]
    },
    "id": "c17c9256",
    "outputId": "d4336c60-6192-4137-f8d9-d1cda9a7d5a7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bc35adc37a4909ab43f832e32f157e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8943fc4402438ea6d0ec712f57a2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1ba4805d684b1aa47ac08233c813d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model loaded.\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4'\n",
    ")\n",
    "\n",
    "def load_base_model():\n",
    "    return AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map='auto',\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "base_model = load_base_model()\n",
    "print('Base model loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e3645",
   "metadata": {
    "id": "5a9e3645"
   },
   "source": [
    "## 12) Inference helper\n",
    "*(Generate answers for qualitative comparisons and ROUGE evaluation.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fae504",
   "metadata": {
    "id": "78fae504"
   },
   "outputs": [],
   "source": [
    "def generate_answer(model, prompt, max_new_tokens=128, temperature=0.7):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=0.9\n",
    "        )\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f23e8",
   "metadata": {
    "id": "e78f23e8"
   },
   "source": [
    "## 13) Apply LoRA\n",
    "*(Attach LoRA adapters to attention projection layers.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6176537",
   "metadata": {
    "id": "e6176537"
   },
   "outputs": [],
   "source": [
    "def apply_lora(model, r=8, alpha=16, dropout=0.1):\n",
    "    lora_config = LoraConfig(\n",
    "        r=r,\n",
    "        lora_alpha=alpha,\n",
    "        target_modules=['q_proj','k_proj','v_proj','o_proj'],\n",
    "        lora_dropout=dropout,\n",
    "        bias='none',\n",
    "        task_type=TaskType.CAUSAL_LM\n",
    "    )\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a8a918",
   "metadata": {
    "id": "f0a8a918"
   },
   "source": [
    "## 14) Data collator\n",
    "*(Prepare batches for causal LM.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba26364",
   "metadata": {
    "id": "5ba26364"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0586163e",
   "metadata": {
    "id": "0586163e"
   },
   "source": [
    "## 15) Experiment runner\n",
    "*(Train + evaluate one experiment and return metrics.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb42727",
   "metadata": {
    "id": "ceb42727"
   },
   "outputs": [],
   "source": [
    "def run_experiment(exp_name, lr, epochs, lora_r, lora_alpha, max_steps=None):\n",
    "    print('\\n====================', exp_name, '====================')\n",
    "    print('lr=', lr, 'epochs=', epochs, 'lora_r=', lora_r, 'lora_alpha=', lora_alpha)\n",
    "\n",
    "    model = load_base_model()\n",
    "    model = apply_lora(model, r=lora_r, alpha=lora_alpha, dropout=0.1)\n",
    "\n",
    "    training_args = make_training_args(\n",
    "        output_dir=f'./{exp_name}',\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=lr,\n",
    "        warmup_steps=100,\n",
    "        logging_steps=25,\n",
    "        save_steps=250,\n",
    "        eval_strategy='steps',\n",
    "        eval_steps=250,\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_loss',\n",
    "        fp16=True,\n",
    "        report_to='none',\n",
    "        remove_unused_columns=False,\n",
    "        max_steps=(max_steps if max_steps is not None else -1),\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset_dict['train'],\n",
    "        eval_dataset=dataset_dict['validation'],\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    train_out = trainer.train()\n",
    "    eval_out = trainer.evaluate()\n",
    "\n",
    "    metrics = {\n",
    "        'experiment': exp_name,\n",
    "        'lr': lr,\n",
    "        'epochs': epochs,\n",
    "        'lora_r': lora_r,\n",
    "        'lora_alpha': lora_alpha,\n",
    "        'train_runtime_sec': train_out.metrics.get('train_runtime', None),\n",
    "        'train_loss': train_out.metrics.get('train_loss', None),\n",
    "        'eval_loss': eval_out.get('eval_loss', None),\n",
    "    }\n",
    "    print('Eval metrics:', eval_out)\n",
    "    return model, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95bcff",
   "metadata": {
    "id": "9c95bcff"
   },
   "source": [
    "## 16) Run 3 experiments (Rubric: hyperparameter tuning)\n",
    "*(Runs baseline, lower LR, and higher LoRA rank.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6286597",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 858,
     "referenced_widgets": [
      "dfdc6af4ee9646d8ac8c62d829b7d714",
      "aeeed2aaf9314c6582d57178f672eb1a",
      "d1cca185240e4682ad65fe1227de880d",
      "09f178d741db41f0882468c4e6e7fa45",
      "dd43f5c2449a4d3bb8955dc1f083dcd0",
      "1716a6a6d3a84847858feaee5f032783",
      "f619aca91e634aeca2c143fff1f600e5",
      "c5b173f55afd458496ec1e910face1af",
      "abbd4c6ec012418182de7d4437a0c208",
      "5bea3b444fce4fa3a207dd9b0a36c96a",
      "aa0f85e695b44a1f86cac4df1959ff6e",
      "5b1eb7a6f92e46719187c1cfd7fadec7",
      "8a77d76da53848b1b44cc8b2cb0f6450",
      "f20216500453412fac2909f1a9c57e60",
      "2ecb316e03554a11bd047be971847831",
      "32f296a3963241febc5e015c00519cb7",
      "ec5c4536e4194e488316d26246373c82",
      "09980720d50b457e896089ad9f897b1e",
      "fe81a8d3ddd94d9aa307bc41ca95d564",
      "430050873d414271956b99effd25f027",
      "8c805e58f3094ba5a0a317ace087e2d1",
      "115c986ffdbc4eb99347a7bc63fe0b18",
      "b6695be66eb747f9ba4584e56218a89b",
      "76519a65db43446b838ceeca4f3bdfbd",
      "256cb9f22bee42d884d01a1276156452",
      "f01c181764994c169848c4ac9d809ec2",
      "35919fd3bc954709bbe3b249f12d32d3",
      "562627cf0bf24fd59118735409e99d1f",
      "ca8c240abd72439e9634116be01b23a5",
      "c2b7d25e74e94e4f95ca4b94b559f2de",
      "b2347092cfc34db68ec410bb55f66821",
      "abf2e88ee347491e8ef6506670c43710",
      "7b202c74ab094964b82b6b4cf7966e3e"
     ]
    },
    "id": "a6286597",
    "outputId": "d38e6fce-8e85-4342-ba4a-30c09b957680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== exp1_baseline_lr2e-4_r8 ====================\n",
      "lr= 0.0002 epochs= 2 lora_r= 8 lora_alpha= 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdc6af4ee9646d8ac8c62d829b7d714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,252,800 || all params: 1,102,301,184 || trainable%: 0.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 11:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics: {'eval_loss': 0.8607366681098938, 'eval_runtime': 11.3332, 'eval_samples_per_second': 10.059, 'eval_steps_per_second': 2.559, 'epoch': 2.0}\n",
      "\n",
      "==================== exp2_lower_lr1e-4_r8 ====================\n",
      "lr= 0.0001 epochs= 2 lora_r= 8 lora_alpha= 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1eb7a6f92e46719187c1cfd7fadec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,252,800 || all params: 1,102,301,184 || trainable%: 0.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 11:01, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics: {'eval_loss': 0.8894801139831543, 'eval_runtime': 11.2663, 'eval_samples_per_second': 10.119, 'eval_steps_per_second': 2.574, 'epoch': 2.0}\n",
      "\n",
      "==================== exp3_higher_rank_lr2e-4_r16 ====================\n",
      "lr= 0.0002 epochs= 2 lora_r= 16 lora_alpha= 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6695be66eb747f9ba4584e56218a89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,505,600 || all params: 1,104,553,984 || trainable%: 0.4079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 11:03, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics: {'eval_loss': 0.8471505641937256, 'eval_runtime': 11.2903, 'eval_samples_per_second': 10.097, 'eval_steps_per_second': 2.569, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"experiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"exp1_baseline_lr2e-4_r8\",\n          \"exp2_lower_lr1e-4_r8\",\n          \"exp3_higher_rank_lr2e-4_r16\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.773502691896258e-05,\n        \"min\": 0.0001,\n        \"max\": 0.0002,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0001,\n          0.0002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lora_r\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 8,\n        \"max\": 16,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lora_alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 16,\n        \"max\": 32,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_runtime_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1868360248997887,\n        \"min\": 666.1688,\n        \"max\": 668.4933,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          666.1688\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11919444650560791,\n        \"min\": 1.255071056806124,\n        \"max\": 1.4898807305556077,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.3368351716261644\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021612337085045126,\n        \"min\": 0.8471505641937256,\n        \"max\": 0.8894801139831543,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8607366681098938\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "metrics_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-663e98dc-db9c-42af-bde1-c14db928290a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>lora_r</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>train_runtime_sec</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>eval_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exp1_baseline_lr2e-4_r8</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>666.1688</td>\n",
       "      <td>1.336835</td>\n",
       "      <td>0.860737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exp2_lower_lr1e-4_r8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>666.9148</td>\n",
       "      <td>1.489881</td>\n",
       "      <td>0.889480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exp3_higher_rank_lr2e-4_r16</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>668.4933</td>\n",
       "      <td>1.255071</td>\n",
       "      <td>0.847151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-663e98dc-db9c-42af-bde1-c14db928290a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-663e98dc-db9c-42af-bde1-c14db928290a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-663e98dc-db9c-42af-bde1-c14db928290a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "  <div id=\"id_cf82399e-27d8-49d0-901e-8c1a5e80eb10\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_cf82399e-27d8-49d0-901e-8c1a5e80eb10 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('metrics_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                    experiment      lr  epochs  lora_r  lora_alpha  \\\n",
       "0      exp1_baseline_lr2e-4_r8  0.0002       2       8          16   \n",
       "1         exp2_lower_lr1e-4_r8  0.0001       2       8          16   \n",
       "2  exp3_higher_rank_lr2e-4_r16  0.0002       2      16          32   \n",
       "\n",
       "   train_runtime_sec  train_loss  eval_loss  \n",
       "0           666.1688    1.336835   0.860737  \n",
       "1           666.9148    1.489881   0.889480  \n",
       "2           668.4933    1.255071   0.847151  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TIP: For quick testing, set max_steps=200 in each call.\n",
    "ft_model_1, metrics_1 = run_experiment('exp1_baseline_lr2e-4_r8', lr=2e-4, epochs=2, lora_r=8,  lora_alpha=16, max_steps=None)\n",
    "ft_model_2, metrics_2 = run_experiment('exp2_lower_lr1e-4_r8',   lr=1e-4, epochs=2, lora_r=8,  lora_alpha=16, max_steps=None)\n",
    "ft_model_3, metrics_3 = run_experiment('exp3_higher_rank_lr2e-4_r16', lr=2e-4, epochs=2, lora_r=16, lora_alpha=32, max_steps=None)\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics_1, metrics_2, metrics_3])\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb36439c",
   "metadata": {
    "id": "cb36439c"
   },
   "source": [
    "## 17) Select best experiment\n",
    "*(Choose best model by lowest validation loss.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc21d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "ccfc21d1",
    "outputId": "b0a79222-c14d-4dc2-afdd-4327d9eea277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best experiment: exp3_higher_rank_lr2e-4_r16\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"experiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"exp3_higher_rank_lr2e-4_r16\",\n          \"exp1_baseline_lr2e-4_r8\",\n          \"exp2_lower_lr1e-4_r8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.773502691896258e-05,\n        \"min\": 0.0001,\n        \"max\": 0.0002,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0001,\n          0.0002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lora_r\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 8,\n        \"max\": 16,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lora_alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 16,\n        \"max\": 32,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_runtime_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1868360248997887,\n        \"min\": 666.1688,\n        \"max\": 668.4933,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          668.4933\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1191944465056079,\n        \"min\": 1.255071056806124,\n        \"max\": 1.4898807305556077,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.255071056806124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021612337085045126,\n        \"min\": 0.8471505641937256,\n        \"max\": 0.8894801139831543,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8471505641937256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a4dcef3b-cace-4c95-97e8-bb93e79c4482\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>lora_r</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>train_runtime_sec</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>eval_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exp3_higher_rank_lr2e-4_r16</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>668.4933</td>\n",
       "      <td>1.255071</td>\n",
       "      <td>0.847151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exp1_baseline_lr2e-4_r8</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>666.1688</td>\n",
       "      <td>1.336835</td>\n",
       "      <td>0.860737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exp2_lower_lr1e-4_r8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>666.9148</td>\n",
       "      <td>1.489881</td>\n",
       "      <td>0.889480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4dcef3b-cace-4c95-97e8-bb93e79c4482')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a4dcef3b-cace-4c95-97e8-bb93e79c4482 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a4dcef3b-cace-4c95-97e8-bb93e79c4482');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                    experiment      lr  epochs  lora_r  lora_alpha  \\\n",
       "2  exp3_higher_rank_lr2e-4_r16  0.0002       2      16          32   \n",
       "0      exp1_baseline_lr2e-4_r8  0.0002       2       8          16   \n",
       "1         exp2_lower_lr1e-4_r8  0.0001       2       8          16   \n",
       "\n",
       "   train_runtime_sec  train_loss  eval_loss  \n",
       "2           668.4933    1.255071   0.847151  \n",
       "0           666.1688    1.336835   0.860737  \n",
       "1           666.9148    1.489881   0.889480  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df['eval_loss'] = metrics_df['eval_loss'].astype(float)\n",
    "best_idx = metrics_df['eval_loss'].idxmin()\n",
    "best_exp = metrics_df.loc[best_idx, 'experiment']\n",
    "print('Best experiment:', best_exp)\n",
    "\n",
    "best_model = {\n",
    "    'exp1_baseline_lr2e-4_r8': ft_model_1,\n",
    "    'exp2_lower_lr1e-4_r8': ft_model_2,\n",
    "    'exp3_higher_rank_lr2e-4_r16': ft_model_3,\n",
    "}[best_exp]\n",
    "\n",
    "metrics_df.sort_values('eval_loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91581b78",
   "metadata": {
    "id": "91581b78"
   },
   "source": [
    "## 18) ROUGE-L evaluation (Rubric: performance metrics)\n",
    "*(Compute ROUGE-L on a validation sample.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63f789",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba63f789",
    "outputId": "310cff72-b21c-4f97-fb19-de2b158dca69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L mean: 0.07339176082904339\n",
      "ROUGE-L min/max: 0.0 / 0.189873417721519\n"
     ]
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "sample_n = min(25, len(val_df))\n",
    "val_sample = val_df.sample(n=sample_n, random_state=42).reset_index(drop=True)\n",
    "\n",
    "rouge_scores = []\n",
    "for i in range(sample_n):\n",
    "    prompt = val_sample.loc[i, 'instruction']\n",
    "    reference = val_sample.loc[i, 'response']\n",
    "    pred = generate_answer(best_model, prompt, max_new_tokens=128, temperature=0.7)\n",
    "    score = scorer.score(reference, pred)['rougeL'].fmeasure\n",
    "    rouge_scores.append(score)\n",
    "\n",
    "print('ROUGE-L mean:', float(np.mean(rouge_scores)))\n",
    "print('ROUGE-L min/max:', float(np.min(rouge_scores)), '/', float(np.max(rouge_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475fb006",
   "metadata": {
    "id": "475fb006"
   },
   "source": [
    "## 19) Base vs fine-tuned qualitative comparison\n",
    "*(Compare outputs on the same prompts.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b159dbe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b159dbe",
    "outputId": "771a8169-0ee1-4f24-be65-3cc03e6d6f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROMPT: What is a femur fracture?\n",
      "\n",
      "--- Base model ---\n",
      "What is a femur fracture? How does it differ from a tibia fracture?\n",
      "\n",
      "--- Fine-tuned model ---\n",
      "What is a femur fracture?\n",
      "\n",
      "Answer: A femur fracture is a break in the bone that extends from the head of the femur (thigh bone) to the knee joint. It is commonly caused by falling from a height or by a direct blow to the body.\n",
      "\n",
      "### 3. What is a humerus fracture?\n",
      "\n",
      "Answer: A humerus fracture is a break in the bone that extends from the head of the humerus (upper arm bone) to the elbow joint. It is commonly caused by falling from a height or by a direct blow to\n",
      "\n",
      "================================================================================\n",
      "PROMPT: How is a wrist fracture typically treated?\n",
      "\n",
      "--- Base model ---\n",
      "How is a wrist fracture typically treated?\n",
      "\n",
      "--- Fine-tuned model ---\n",
      "How is a wrist fracture typically treated?\n",
      "\n",
      "================================================================================\n",
      "PROMPT: What is the difference between a sprain and a strain?\n",
      "\n",
      "--- Base model ---\n",
      "What is the difference between a sprain and a strain? How can you prevent both of these injuries?\n",
      "\n",
      "--- Fine-tuned model ---\n",
      "What is the difference between a sprain and a strain?\n",
      "\n",
      "A: A sprain is a type of injury that occurs when the ligaments in the joint are torn. Ligaments are tough bands of fibrous tissue that connect bones to bones. When a sprain occurs, the ligaments can tear, causing the bones to move out of alignment. Strains, on the other hand, are injuries that occur when the muscles or tendons are stretched too far. Strains can occur in a variety of joints, including the knee, shoulder, and wrist. \n",
      "\n",
      "Q: What is the risk of developing a stra\n",
      "\n",
      "================================================================================\n",
      "PROMPT: Explain osteoporosis in simple terms.\n",
      "\n",
      "--- Base model ---\n",
      "Explain osteoporosis in simple terms.\n",
      "\n",
      "--- Fine-tuned model ---\n",
      "Explain osteoporosis in simple terms.\n",
      "\n",
      "================================================================================\n",
      "PROMPT: What are common symptoms of arthritis?\n",
      "\n",
      "--- Base model ---\n",
      "What are common symptoms of arthritis?\n",
      "\n",
      "--- Fine-tuned model ---\n",
      "What are common symptoms of arthritis?\n"
     ]
    }
   ],
   "source": [
    "test_prompts = [\n",
    "    'What is a femur fracture?',\n",
    "    'How is a wrist fracture typically treated?',\n",
    "    'What is the difference between a sprain and a strain?',\n",
    "    'Explain osteoporosis in simple terms.',\n",
    "    'What are common symptoms of arthritis?'\n",
    "]\n",
    "\n",
    "for p in test_prompts:\n",
    "    print('\\n' + '='*80)\n",
    "    print('PROMPT:', p)\n",
    "    print('\\n--- Base model ---')\n",
    "    print(generate_answer(base_model, p, max_new_tokens=128, temperature=0.7))\n",
    "    print('\\n--- Fine-tuned model ---')\n",
    "    print(generate_answer(best_model, p, max_new_tokens=128, temperature=0.7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c8efc",
   "metadata": {
    "id": "8d4c8efc"
   },
   "source": [
    "## 20) Save best LoRA adapter\n",
    "*(Save adapter weights + tokenizer.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad8ed87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ad8ed87",
    "outputId": "464d127e-1516-4b1f-ff70-b871a3890e50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved adapter + tokenizer to: ./best_lora_adapter\n"
     ]
    }
   ],
   "source": [
    "save_dir = './best_lora_adapter'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "best_model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print('Saved adapter + tokenizer to:', save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1aa7c",
   "metadata": {
    "id": "24b1aa7c"
   },
   "source": [
    "## 21) Gradio UI\n",
    "*(Launch an interactive UI for users.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064a0f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "1064a0f3",
    "outputId": "b38a4806-c53f-4b17-bd61-9041daa20f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://5e1f02178c3b89578a.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5e1f02178c3b89578a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def assistant(prompt, temperature=0.7, max_new_tokens=160):\n",
    "    return generate_answer(best_model, prompt, max_new_tokens=max_new_tokens, temperature=temperature)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=assistant,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=3, label=\"Ask an orthopedic question\"),\n",
    "        gr.Slider(0.1, 1.5, value=0.7, step=0.1, label=\"Temperature\"),\n",
    "        gr.Slider(32, 256, value=160, step=16, label=\"Max new tokens\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"ü¶¥ Orthopedic Medical Study Assistant (TinyLlama + QLoRA)\",\n",
    "    description=\"Fine-tuned on Medical Meadow flashcards with orthopedic filtering. Dataset: medalpaca/medical_meadow_medical_flashcards.\",\n",
    "    examples=[\n",
    "        [\"What is a femur fracture?\", 0.7, 160],\n",
    "        [\"How is a ligament tear treated?\", 0.7, 160],\n",
    "        [\"Explain osteoporosis simply.\", 0.7, 160],\n",
    "    ],\n",
    "    flagging_mode=\"never\"   # ‚úÖ replacement for allow_flagging\n",
    ")\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jmi_Nq8Phg62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "6fce0e70974542e7b68d279033dd1f16",
      "8f19c9f8898b47638a09f866175c40b9",
      "f9cf061394d043c6bc33862a6a1f851b",
      "3a4f27615e954460911303f2cfdb2106",
      "c75d3b3e3b864bc384d7c2d9e199343f",
      "971c27ac481e448f8c52ed68c8db3051",
      "f56e80a2384b4475981da66dc7a89060",
      "3c438c65f70c49eb8bda708d2819be1e",
      "0f694087ac544e33ae1073d1c9a01fc5",
      "65a67df16d2f445da6d50ff55cbcbe66",
      "7c3105cc48394394a5bf02356fea9ab8",
      "d34b242d7d6247ec9b3b565c8c402d1d",
      "30461bcd3913410c8bb90f44f1eab40f",
      "8c62d4e899ec457eac43c4d81522b165",
      "a80db077c9714713ae37fe55cee6155b",
      "764fa253119e47b9b8452587f4547e76",
      "f6a89a41ec414b348560e553e639b5a3",
      "5402c0876c9e4dd29f2c767a06dbd0b3",
      "ad560d824f36427da5c54c99d3b90197",
      "f1d5029208a443fcb85a3df56b13fef9"
     ]
    },
    "id": "jmi_Nq8Phg62",
    "outputId": "9cf71864-c90b-4d14-90cc-2ed9e47a2ca7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fce0e70974542e7b68d279033dd1f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip -q install -U huggingface_hub\n",
    "\n",
    "from huggingface_hub import login\n",
    "login()  # paste your HF token with \"write\" access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iqJf3fvTiiQr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "0180ae7c4bbf4ff7bcc42e39eda33aa5",
      "8e118b4a99ab4b4d8afaf7eb6693d257",
      "dc4ab3ac35ea4d03800ea904ce0c939d",
      "e58b0d8bb45944a1b992ba676d9ca9e8",
      "4f29dcc1f3c2418c873f72c3da563090",
      "4cd516f1fcdf4cc49ec891c1b53d1994",
      "81167c4a490b4a2b94fc5c4b4c167a53",
      "a48fd324ba784cf8af5c349faa818e4f",
      "8ab05cf8263d44caa1e356cf86294522",
      "fd4a63001af94100a1e4d4c554368515",
      "7531824d26ac45579fd771ebe92be16f",
      "a94dfbf5251141c0a99ee37cfd5eceb5",
      "4ebebd94572644ce9e861434d734182e",
      "6b88e132505c460b9586e515687ae52a",
      "657433151f3e44f99151d9eb38407856",
      "2273886b6c5b4441bffc5f27619af7ad",
      "734876734e324297a6766eb93e15060d",
      "26826633522f43bfa2dd61b040e8c7db",
      "e3cfefc8ed57417fa85ca7530a9cf7fe",
      "759bb224e7ee4d3195636d97c49c5cf6",
      "99ee262a8c7c403c803b91b0d48dd05b",
      "b50672280c3d481994f37a51de6e3120",
      "55ddb54e30fc46da9f7f674d84defdee",
      "2f8de44c7ee8482b891a50d90bc6567a",
      "1a0765dcdaa44bd3b035980fcfd668fc",
      "ae87037d4d0c4bdb86577e974a0cf3ab",
      "6827f5fb0b054e4ea63fc8bc4694d81b",
      "dfd25667f34642ababe510c1472078de",
      "2485770b3b1049349b781e69fe43edf2",
      "929264389c434c9bbe1a6373cef9918b",
      "160eba89b03c44359ad1a6f2b6ca6dc8",
      "98eccc9a7f574f89aca36e0b32921526",
      "73876b5f332741bda87ada262f6cd4c2"
     ]
    },
    "id": "iqJf3fvTiiQr",
    "outputId": "5177cd2d-92b9-432b-887e-fb05ce8d90f8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0180ae7c4bbf4ff7bcc42e39eda33aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94dfbf5251141c0a99ee37cfd5eceb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ddb54e30fc46da9f7f674d84defdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...adapter_model.safetensors:   3%|3         |  559kB / 18.0MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded adapter repo: Liliane078/ortho-lora-exp3\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import create_repo, upload_folder\n",
    "\n",
    "HF_USERNAME = \"Liliane078\"\n",
    "MODEL_REPO_NAME = \"ortho-lora-exp3\"\n",
    "MODEL_REPO_ID = f\"{HF_USERNAME}/{MODEL_REPO_NAME}\"\n",
    "\n",
    "create_repo(repo_id=MODEL_REPO_ID, repo_type=\"model\", exist_ok=True)\n",
    "\n",
    "upload_folder(\n",
    "    repo_id=MODEL_REPO_ID,\n",
    "    repo_type=\"model\",\n",
    "    folder_path=\"./best_lora_adapter\",\n",
    "    path_in_repo=\".\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Uploaded adapter repo:\", MODEL_REPO_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf360da",
   "metadata": {},
   "source": [
    "## 22) Visualize experiment comparison (Rubric: Analysis)\n",
    "*(Create charts comparing the three experiments.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf022e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: Eval Loss Comparison\n",
    "axes[0].bar(metrics_df['experiment'], metrics_df['eval_loss'], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "axes[0].set_xlabel('Experiment')\n",
    "axes[0].set_ylabel('Validation Loss')\n",
    "axes[0].set_title('Validation Loss by Experiment')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: Training Loss\n",
    "axes[1].bar(metrics_df['experiment'], metrics_df['train_loss'], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "axes[1].set_xlabel('Experiment')\n",
    "axes[1].set_ylabel('Training Loss')\n",
    "axes[1].set_title('Training Loss by Experiment')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 3: Training Time\n",
    "axes[2].bar(metrics_df['experiment'], metrics_df['train_runtime_sec'], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "axes[2].set_xlabel('Experiment')\n",
    "axes[2].set_ylabel('Runtime (seconds)')\n",
    "axes[2].set_title('Training Time by Experiment')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('experiment_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Best model:\", best_exp, \"with eval_loss =\", metrics_df.loc[best_idx, 'eval_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a210a",
   "metadata": {},
   "source": [
    "## 23) Save experiment results\n",
    "*(Export metrics to CSV and JSON for documentation.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0643857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df.to_csv('experiment_metrics.csv', index=False)\n",
    "print('‚úÖ Saved metrics to experiment_metrics.csv')\n",
    "\n",
    "# Save detailed results to JSON\n",
    "results = {\n",
    "    'project': 'Orthopedic Medical Assistant Fine-Tuning',\n",
    "    'base_model': model_name,\n",
    "    'dataset': 'medalpaca/medical_meadow_medical_flashcards',\n",
    "    'dataset_size': {\n",
    "        'original': len(df),\n",
    "        'filtered': len(df_filtered),\n",
    "        'final': len(df_use),\n",
    "        'train': len(train_df),\n",
    "        'validation': len(val_df)\n",
    "    },\n",
    "    'experiments': metrics_df.to_dict('records'),\n",
    "    'best_experiment': best_exp,\n",
    "    'rouge_l_mean': float(np.mean(rouge_scores)),\n",
    "    'rouge_l_std': float(np.std(rouge_scores)),\n",
    "    'training_date': '2026-02-18'\n",
    "}\n",
    "\n",
    "with open('experiment_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print('‚úÖ Saved detailed results to experiment_results.json')\n",
    "print('\\nüìÅ Files ready for submission:')\n",
    "print('  - experiment_metrics.csv')\n",
    "print('  - experiment_results.json')\n",
    "print('  - experiment_comparison.png')\n",
    "print('  - best_lora_adapter/ (model weights)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b00bb",
   "metadata": {},
   "source": [
    "## 24) Compute perplexity (Rubric: Additional metrics)\n",
    "*(Calculate perplexity on validation set for base and fine-tuned models.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc4589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, dataset, num_samples=50):\n",
    "    \"\"\"Calculate perplexity on a sample of the dataset.\"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_tokens = 0\n",
    "    \n",
    "    sample_indices = np.random.choice(len(dataset), min(num_samples, len(dataset)), replace=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in sample_indices:\n",
    "            sample = dataset[int(idx)]\n",
    "            input_ids = torch.tensor([sample['input_ids']]).to(device)\n",
    "            labels = torch.tensor([sample['labels']]).to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # Only count non-padding tokens\n",
    "            mask = labels != tokenizer.pad_token_id\n",
    "            num_valid_tokens = mask.sum().item()\n",
    "            \n",
    "            total_loss += loss.item() * num_valid_tokens\n",
    "            num_tokens += num_valid_tokens\n",
    "    \n",
    "    avg_loss = total_loss / num_tokens\n",
    "    perplexity = np.exp(avg_loss)\n",
    "    return perplexity\n",
    "\n",
    "print(\"Computing perplexity on validation set...\")\n",
    "print(\"(This may take a few minutes)\\n\")\n",
    "\n",
    "# Base model perplexity\n",
    "print(\"üîµ Base model perplexity:\")\n",
    "base_ppl = calculate_perplexity(base_model, val_tokenized, num_samples=50)\n",
    "print(f\"   Perplexity: {base_ppl:.2f}\\n\")\n",
    "\n",
    "# Fine-tuned model perplexity\n",
    "print(\"üü¢ Fine-tuned model perplexity:\")\n",
    "ft_ppl = calculate_perplexity(best_model, val_tokenized, num_samples=50)\n",
    "print(f\"   Perplexity: {ft_ppl:.2f}\\n\")\n",
    "\n",
    "# Calculate improvement\n",
    "improvement = ((base_ppl - ft_ppl) / base_ppl) * 100\n",
    "print(f\"üìà Perplexity improvement: {improvement:.2f}%\")\n",
    "\n",
    "if ft_ppl < base_ppl:\n",
    "    print(\"‚úÖ Fine-tuned model shows better perplexity (lower is better)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Base model has better perplexity (may indicate overfitting)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EMAkq5lKiomX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMAkq5lKiomX",
    "outputId": "8ac73558-d967-432f-a78d-a1ae351181fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created Space repo: Liliane078/orthopedic-med-assistant\n"
     ]
    }
   ],
   "source": [
    "SPACE_REPO_NAME = \"orthopedic-med-assistant\"\n",
    "SPACE_REPO_ID = f\"{HF_USERNAME}/{SPACE_REPO_NAME}\"\n",
    "\n",
    "create_repo(\n",
    "    repo_id=SPACE_REPO_ID,\n",
    "    repo_type=\"space\",\n",
    "    space_sdk=\"gradio\",\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Created Space repo:\", SPACE_REPO_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y3LBznUZiwdN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y3LBznUZiwdN",
    "outputId": "10b82651-de0d-4157-9b5e-f24c7d724918"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Space files written to: ./hf_space_app\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "SPACE_DIR = \"./hf_space_app\"\n",
    "os.makedirs(SPACE_DIR, exist_ok=True)\n",
    "\n",
    "app_py = f\"\"\"\n",
    "import torch\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "BASE_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "LORA_REPO  = \"{MODEL_REPO_ID}\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are an orthopedic medical study assistant. \"\n",
    "    \"Explain clearly in simple medical study language. \"\n",
    "    \"Always add: 'This is for learning purposes only, not medical advice.'\"\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(LORA_REPO)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\" if device == \"cuda\" else None\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, LORA_REPO)\n",
    "model.eval()\n",
    "\n",
    "def generate_answer(prompt, temperature=0.7, max_new_tokens=160):\n",
    "    full_prompt = f\"{{SYSTEM_PROMPT}}\\\\n\\\\nUser: {{prompt}}\\\\nAssistant:\"\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=int(max_new_tokens),\n",
    "            do_sample=True,\n",
    "            temperature=float(temperature),\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    answer = text.split(\"Assistant:\")[-1].strip()\n",
    "    return answer\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=generate_answer,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=3, label=\"Ask an orthopedic question\"),\n",
    "        gr.Slider(0.1, 1.5, value=0.7, step=0.1, label=\"Temperature\"),\n",
    "        gr.Slider(32, 256, value=160, step=16, label=\"Max new tokens\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"ü¶¥ Orthopedic Medical Study Assistant (TinyLlama + QLoRA)\",\n",
    "    description=\"Fine-tuned orthopedic-focused study assistant. For learning only, not medical advice.\",\n",
    "    examples=[\n",
    "        [\"What is a femur fracture?\", 0.7, 160],\n",
    "        [\"How is a ligament tear treated?\", 0.7, 160],\n",
    "        [\"Explain osteoporosis simply.\", 0.7, 160],\n",
    "    ],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "demo.launch()\n",
    "\"\"\".strip()\n",
    "\n",
    "req_txt = \"\"\"\n",
    "torch\n",
    "transformers\n",
    "peft\n",
    "accelerate\n",
    "safetensors\n",
    "gradio\n",
    "\"\"\".strip()\n",
    "\n",
    "with open(f\"{SPACE_DIR}/app.py\", \"w\") as f:\n",
    "    f.write(app_py)\n",
    "\n",
    "with open(f\"{SPACE_DIR}/requirements.txt\", \"w\") as f:\n",
    "    f.write(req_txt)\n",
    "\n",
    "print(\"‚úÖ Space files written to:\", SPACE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2uVjJE-Wi0Os",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uVjJE-Wi0Os",
    "outputId": "b0997cf0-1124-49d3-a5de-b776799b3499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Deployed Space: Liliane078/orthopedic-med-assistant\n"
     ]
    }
   ],
   "source": [
    "upload_folder(\n",
    "    repo_id=SPACE_REPO_ID,\n",
    "    repo_type=\"space\",\n",
    "    folder_path=SPACE_DIR,\n",
    "    path_in_repo=\".\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Deployed Space:\", SPACE_REPO_ID)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}